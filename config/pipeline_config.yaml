---
# Pipeline Configuration
pipeline:
  name: "databricks-data-pipeline"
  version: "1.0.0"
  environment: "development"

# Data source configurations
sources:
  employees:
    path: "data/input/employees.csv"
    format: "csv"
    schema_type: "complex"
    options:
      header: "true"
      inferSchema: "false"
  
  sales:
    path: "data/input/sales.json"
    format: "json"
    schema_type: "simple"

# Output configurations
outputs:
  bronze_layer:
    path: "data/output/bronze"
    format: "parquet"
    mode: "overwrite"
  
  silver_layer:
    path: "data/output/silver"
    format: "delta"
    mode: "append"
    partition_by:
      - "department"
      - "hire_date"
  
  gold_layer:
    path: "data/output/gold"
    format: "delta"
    mode: "overwrite"

# Spark configurations
spark:
  app_name: "DataPipeline"
  configs:
    spark.sql.adaptive.enabled: "true"
    spark.sql.adaptive.coalescePartitions.enabled: "true"
    spark.sql.shuffle.partitions: "200"
    spark.databricks.delta.optimizeWrite.enabled: "true"
    spark.databricks.delta.autoCompact.enabled: "true"

# Logging configuration
logging:
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
